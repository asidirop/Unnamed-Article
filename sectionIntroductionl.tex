\section{Introduction}\label{introduction}

With the introduction of the well-known \emph{h}-index by Jorge Hirsch a
plethora of bibliometric indices have been proposed to better quantify
the features of scientific output. Existing indices can be categorized
according to the entity under evaluation, i.e. author performance,
journal impact or publication level. In this direction, variations of
the \emph{h}-index have emerged to employ different ranges in citation
accumulation, such as the \emph{g}-index , \emph{hg} and
\emph{h\textsubscript{2}} index . Other approaches perform
normalizations of the calculated index over the number of publications,
age of publications or citations and include but are not limited to the
\emph{h\textsubscript{norm}} index , the contemporary \emph{h}-index
(\emph{h\textsuperscript{cont}}) and trend \emph{h}-index
(\emph{h\textsuperscript{t}}) , \emph{m}-quotient and Bornmann's
\emph{m} (\emph{m\textsubscript{Bor}}) . Analogous efforts have been
made to measure the distribution of citations that contribute to the
calculation of the \emph{h}-index, such as \emph{h\textsubscript{rat}} ,
tapered \emph{h-}index (\emph{h\textsubscript{tap}}) and \emph{w} of
Wohlin , whilst another set of works attempt to include different areas
around the citation curve into a single number metric, such as the
excess or \emph{e}-index , the set of indices introduced by Jin
(\emph{A}, \emph{R} and \emph{AR} indices) and the more recent
Perfectionism Index or \emph{PI}-index , etc.

Given the wide range of bibliometric indices available in literature,
their interrelations and correlations with one another have been
extensively studied in , , and . A taxonomy of 108 author-level indices
has been performed in investigating their usefulness, their complexity
of calculation and the different publishing features they represent. All
the aforementioned studies, report a high degree of correlation between
the \emph{h}-index and its variants, thus identifying overlapping
information conveyed by the large variety of existing bibliometric
indices. Consequently, to achieve a fair evaluation of scientific output
one must consider multiple uncorrelated indices expressing different
scientific qualities calculated from bibliometric data.

In an effort to achieve a fair and universal ranking of scientific
entities Wolcott et al. proposed the use of both time-dependent and
-independent factors as part of a classification scheme to assign
relative importance ranking to publications based on their probability
of being highly cited. Relative performance at publication level has
been also incorporated into a co-citation based indicator in , whereas
for journal ranking an attempt to broaden the evaluation of journals
using altmetrics is presented in . Tsai et al identified domain
dependent correlations between various journal rankings and produced a
unified journal ranking as a combination of existing ones. In the
variation of different citers was used as a proxy for publication
ranking, whereas proposes the application of performance classes to
evaluate research at country and institutional level.

Each bibliometric index produces a different rank list with strict
scores for the same group of scientists. Having to deal with this storm
of valuable indicators, the need arises for a general classification
scheme of scientific entities according to multiple evaluation metrics.
The quantification of abstract concepts such as ``scientific impact''
allow for tolerance limits to be fair. Therefore, it would be more
appropriate to create ranking levels instead of strict scoring, where
multiple researchers can be ranked at the same level. In this direction,
the use of the \emph{skyline operator} was proposed in a previous work
to select from a set of researchers those that cannot be outperformed by
any other from a pool of scientists. In other words, outstanding
scientists are identified in one or more dimensions (i.e., features) but
not necessarily in all of the dimensions. This way credit can be
attributed to various publishing patterns and, thus, scientists that
outperform others in certain attributes can also be distinguished. Of
crucial importance to the skyline operator's computation is the
selection of dimensions, i.e., the evaluation indicators. Dependent on
the perspective of the evaluation to be performed various appropriate
metrics may be selected and the resulting skyline set will adjust
accordingly.

In the present work we expand upon the concept of the skyline operator
by incorporating the dominating groups of scientists into universal
ranking levels, and introducing a new indicator based on the relative
ranking a scientist has achieved, namely Rainbow Ranking scheme; Figure
1 justifies the name.

The rest of the paper is organized as follows: The next section
describes the dataset used in our analysis. The applied methodologies
are presented in the third section, in which we introduce the new
indicator and the process of its calculation. In the fourth section, the
results of the study are given, whereas conclusions appear in the final
section.